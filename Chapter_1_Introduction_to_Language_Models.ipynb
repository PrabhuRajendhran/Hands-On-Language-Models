{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDe7DsPWmEBV"
      },
      "source": [
        "<h1>Chapter 1 - Introduction to Language Models</h1>\n",
        "<i>Exploring the exciting field of Language AI</i>\n",
        "\n",
        "\n",
        "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\"><img src=\"https://img.shields.io/badge/Buy%20the%20Book!-grey?logo=amazon\"></a>\n",
        "<a href=\"https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/\"><img src=\"https://img.shields.io/badge/O'Reilly-white.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMzQiIGhlaWdodD0iMjciIHZpZXdCb3g9IjAgMCAzNCAyNyIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTMiIGN5PSIxNCIgcj0iMTEiIHN0cm9rZT0iI0Q0MDEwMSIgc3Ryb2tlLXdpZHRoPSI0Ii8+CjxjaXJjbGUgY3g9IjMwLjUiIGN5PSIzLjUiIHI9IjMuNSIgZmlsbD0iI0Q0MDEwMSIvPgo8L3N2Zz4K\"></a>\n",
        "<a href=\"https://github.com/HandsOnLLM/Hands-On-Large-Language-Models\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter01/Chapter%201%20-%20Introduction%20to%20Language%20Models.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is for Chapter 1 of the [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) book by [Jay Alammar](https://www.linkedin.com/in/jalammar) and [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/).\n",
        "\n",
        "---\n",
        "\n",
        "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\">\n",
        "<img src=\"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png\" width=\"350\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ek-QILIZ315"
      },
      "source": [
        "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
        "\n",
        "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfCxwqhfZ317"
      },
      "source": [
        "---\n",
        "\n",
        "ðŸ’¡ **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
        "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YZl8RTr2Z319"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install transformers==4.41.2 accelerate==0.31.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXp09JFsFBXi"
      },
      "source": [
        "# Phi-3\n",
        "\n",
        "The first step is to load our model onto the GPU for faster inference. Note that we load the model and tokenizer separately (although that isn't always necessary)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RSNalRXZyTTk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418,
          "referenced_widgets": [
            "a2e6fcba00644435a32c066c7b79de90",
            "6fa119976d7d49a9ab3ba50be104a80c",
            "e90e6cdc39cc4d6aacb3026933f26cf5",
            "9daadf88b56b488ab35358069dd01e5c",
            "d106a2a79621489ea34f197adf59640b",
            "2d6edaf90140437d8c341e1fa20f12fa",
            "f269c1caa2dc4edca65eb90a847ab423",
            "721f099665d34e4198f0556603f46f65",
            "33185b2a149142559112f34a6f8e38fb",
            "53c316df975147ebb134be4f8e477462",
            "0b83c2e1dfa84f688e94f7105ede4e38",
            "4f42145f64d04c8696d11951d94bb5c3",
            "2509ce1c445147049fe6f52cab553617",
            "12bc8ea1b6044ef5be3ad9ab7cf7235d",
            "52686182660d44b7a13d52bd8e083240",
            "f131768036484b1e9b531adbd1d787c6",
            "cbd5e0890d1f4bb2ba3598d73bdeab00",
            "c36309daf9c14da3a0cbd602fc835f13",
            "ac3e156ec0c14ab5be294f3f398bea9b",
            "11b01da969e142289890ac003152f5e8",
            "3a015c7694c142b0b8c0d20a569cac2e",
            "f08ad246290543f59973b48d2f1aee27",
            "12fed040af064cb0aba8f206c5fb5fdb",
            "5b778c07f1d84cebbcd51234758cc60f",
            "73fdb607aac843b1bc2c023082b103cf",
            "1cf1c577d1da4d5cbfaa1bf8f999b06a",
            "a78bd6b0713b4d0e95d8e9fd5f4d55b6",
            "4873a4eaa5d24688a782f5fff45cc3b5",
            "e1158eb112684b74a170aa60691180ee",
            "a3c4515840644867a33fd977a94e2eef",
            "480ede581b0c4788b0d01cd6ef46fd23",
            "b639b991415c4444b0bb27d033e077e4",
            "4bb6d8e66c3f400f93f6a739a8751f1c",
            "89de28993e384a8189eda57e41c8e959",
            "183933c2ec674ef8909ecb3d0814d378",
            "11f8ea1cfd6d49729f77521d618325a4",
            "844d4b82e78d426bb8b7fe58a3d3ffbb",
            "b180899a88c94a1f8d7026ac89a4ddb1",
            "9d7ecd57c8f540b8a68312ca6772cf1b",
            "8925a2708fd946cf9c7cbedece7d3ef8",
            "27a91408e0614950ab5f49b387c36e1e",
            "f35b11cc6355429ea975af3c1293ae45",
            "f23958e708c34efdbfca59b6dbd5454d",
            "d695fd1b2834474a9f1abe23d9116a6a",
            "ba994a6200fb4115ad758403a144c654",
            "9d931b0a5af549a3824485fd454454e6",
            "1c73c8a1a05142ae8c4086ee66b4c662",
            "352694a0a245453996549b0545dd6f19",
            "b16d6d6e9676493eb055cf6df57672da",
            "4b50137345d847ddb641e8e670ec1271",
            "6937f0b22c2146eab3ad70445eebe045",
            "59d9c749302e40d1aa8d4426c8e5c54d",
            "1a39fa9272a14bfcb18a3f9e7a7a5e2c",
            "5d0af1d34a864b5db0c594de39f7814d",
            "14452dc3142947529cb3e2d9bbc43dfb",
            "ea04e1f1000a4ec6a16e65c7c55a7003",
            "276cc2b8cb954d7aa28b25df9f8aeb86",
            "7b7ccf1edb7e42f79e82e10da4119f78",
            "a9ec401564f740d3bac3fceebb26a7dd",
            "b9a6aef0466f4609baab78504304aea6",
            "143cbd05fc67440996427608d6fb0e6b",
            "184121f3524947c7b4845909ea3e84f3",
            "116694e2855d49f68b394c6a405dcf74",
            "d367fbbb55b94582be7423fddecb21e6",
            "0968ed7cbe14445abb595266868f5eb9",
            "1b39949370c147fabc1ba3b9cb07b85b",
            "cebd1bc8731441b998a0112483d3797e",
            "df5e97176319464189fa55c94966a2a4",
            "e29e1c034e4e41688c303ae60b49c5b1",
            "81ec7acf0a8d44b6be9bd31576dbcd96",
            "e61cba6f8f5643c09ad5e1bdd86e6fe8",
            "b0ac36a1552c49148bc3ff6a8819577b",
            "814c21547a204bd8b5c50b84e7519dab",
            "a7f99b0bade8429d8954846c04ef0173",
            "9ca62758c35b40559137ad0b60e46e0e",
            "8899e987c70d46f1b1785946a79a7be5",
            "66dd5e0ee7184dc38f5c97e1318b6dc7",
            "24a06ebe0a9d4b0e8448869f7e9a8205",
            "603f8249e2e74a47a61676c5caa48d44",
            "a0625d662fc046f9bff7680b42499a04",
            "907697e5dce044088cf4d8355084d32a",
            "3bf2a72a87d04b178e81a432610a8368",
            "e1a6e2359ea64bfaa65585430dc735c0",
            "ac90b978ffb74f22b18bc022066b8b9f",
            "7cc94794367b4497bbcf4098e1b1c67e",
            "d058b8206fb14afba9a6b4550a69f2de",
            "9e3211a61a434d348c11621d9c2a4e4f",
            "89e20b44727d46298559f683d7ceb409",
            "ca7f3e0d2e394714931cff530194e872",
            "6e4323bfda2945a892e50f57e79e4347",
            "61ae4830ed674df7ba073c02f5df8fa9",
            "f91e1befc7bc492c9ee11ec34729287a",
            "c8e8ec38cf98444580fba6166d08816d",
            "215b4c0682aa4359a76ce7bf42832d1d",
            "2ea25e2f408e4110a41148490bab1063",
            "865e29bb7fb94427a7762104c567c358",
            "585499a1f8024cfdaca6a582c8a52b83",
            "6109f84d85534111921d53ebb9933330",
            "72f4db763dc544b4a44ff47d1f1087ee",
            "dc0dfc91b7314aad83b5017465385394",
            "8a6a6debc5e74bf2891fc5866f2ba076",
            "21d99f7e854247478fd0c77b9302c1d3",
            "ece1cb0671674e06845def948546e0cb",
            "4ee51139797a4cf4b408c058b5b1cf05",
            "50c96d1bf075482d9cf2ab8d76b1847a",
            "03b2582d3eca47e0bc94ac5cdb547871",
            "4fb87377f59a43e4b5a35a4cfd8d29b1",
            "b88474cbe4524c2eb7fcb0af7c036ee0",
            "951da9030c7048afaefff12bc726f08f",
            "01e75e568af542269d9c6230a165d9b3",
            "b756c0e23bc6423083c89cfaae0aee54",
            "f25284306d7a48ed82529a0ed8ed90d6",
            "1b71b2b0435848c8870d431ebfa0df9e",
            "4322b5cf23b14687b7e42eca6d4c56c7",
            "1362ebbfc9d044cda3ed43dfcdb661fd",
            "c1cbd228459d4993ae5f05d4f9b56d20",
            "0307077162384c27a480468901b16d79",
            "86e1a201e46e4105bc9e6a49c7259a02",
            "b92cf43c4a82441bae45d118c34e6f9e",
            "95954e1168ad41cb8d94337ce82a7106",
            "9088e3d9e5de47a6811842368d181b57",
            "a721d0ac49ba4a669480055a90c460b0",
            "b4e1513f36dc4013b37a133319da625c",
            "a6f1ee7a9a6743fc8664f0298f5a0005",
            "fb60c6806d2f4fadbd2d6e6bfb809195",
            "830089aef12a4f1a87f8bc942c0a378f",
            "1e4745a355d344dcb241c54d284b94e5",
            "0d61bfdde11c4b0e9ebd59417ec69270",
            "f6ef69f8effb417280c6eb6952deed89",
            "78069d039b0543ee9ce9d7cb5f401e90",
            "217c16b8199b4f7db54e69487fea302e",
            "371cc5e715f940c4bc302eebea5c85da"
          ]
        },
        "outputId": "19e01d49-d2e5-49aa-ef8a-1feb0f466d63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2e6fcba00644435a32c066c7b79de90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f42145f64d04c8696d11951d94bb5c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12fed040af064cb0aba8f206c5fb5fdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89de28993e384a8189eda57e41c8e959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba994a6200fb4115ad758403a144c654"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea04e1f1000a4ec6a16e65c7c55a7003"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cebd1bc8731441b998a0112483d3797e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24a06ebe0a9d4b0e8448869f7e9a8205"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca7f3e0d2e394714931cff530194e872"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc0dfc91b7314aad83b5017465385394"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b756c0e23bc6423083c89cfaae0aee54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a721d0ac49ba4a669480055a90c460b0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=False,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdyYYS0E5fEU"
      },
      "source": [
        "Although we can now use the model and tokenizer directly, it's much easier to wrap it in a `pipeline` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DiUi4Wu1FCyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94bf954-322c-4bdc-bfc0-7408fc13bd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        "    do_sample=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD49kysT5mMY"
      },
      "source": [
        "Finally, we create our prompt as a user and give it to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hkR7LBmiyXmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd228852-bdda-4501-c8d8-1c5cef74ce6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Why did the chicken join the band? Because it had the drumsticks!\n"
          ]
        }
      ],
      "source": [
        "# The prompt (user input / query)\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
        "]\n",
        "\n",
        "# Generate output\n",
        "output = generator(messages)\n",
        "print(output[0][\"generated_text\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}